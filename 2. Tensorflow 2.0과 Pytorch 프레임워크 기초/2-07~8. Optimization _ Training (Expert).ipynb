{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow: Optimization & Training (Expert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/  \n",
    "공식 홈페이지에서 설명하는 Expert 버젼을 배워보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note for GPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 과정 돌아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logic](image/logic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](image/model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(input_shape, dtype=tf.float64)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우 공식홈페이지에서 말한 expert한 방법\n",
    "- tf.data 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.mnist\n",
    "\n",
    "# Load Data from MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Add Channel\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "# Data Normalization\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from_tensor_slices()\n",
    "- shuffle()\n",
    "- batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(1000)\n",
    "train_ds = train_ds.batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "# No need to shuffle\n",
    "test_ds = test_ds.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data\n",
    "\n",
    "matplotlib 불러와서 데이터 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 28, 28, 1]), TensorShape([32]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_ds.take()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(32, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in train_ds.take(2):\n",
    "    plt.title(label[0].numpy())\n",
    "    plt.imshow(image[0, :, :, 0], 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras로 학습 할 때는 기존과 같지만, train_ds는 generator라서 그대로 넣을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1934\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0779\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0629\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0545\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0482\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0465\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0429\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0419\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0374\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0377\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0359\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0359\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0351\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0339\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0342\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0327\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0328\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0328\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0313\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0313\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0305\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0305\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0309\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0269\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0296\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0312\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0298\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0306\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0299\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0299\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0279\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0302\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0293\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0285\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0297\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0282\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0275\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0301\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0282\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0308\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0273\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0288\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0293\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0298\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0286\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0282\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0317\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0276\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0289\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0290\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0285\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0261\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0302\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0308\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0263\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0281\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0307\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0290\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0285\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0288\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0296\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0296\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0279\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0297\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0279\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0291\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0297\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0286\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0287\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0300\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0280\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0317\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0290\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0276\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0265\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0277\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0282\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0321\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0306\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0318\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0305\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0342\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0290\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0252\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0270\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0318\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0291\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0296\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0307\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0293\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0324\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0310\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0313\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0314\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0286\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0284\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0286\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0306\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0285\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7ef9ce7d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(train_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss Function\n",
    "- Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss Function를 담을 곳\n",
    "- Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@tf.function - 기존 session 열었던 것처럼 바로 작동 안 하고, 그래프만 만들고 학습이 시작되면 돌아가도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3603036403656006, Accuracy: 11.141666412353516, Test Loss: 2.275181531906128, Test Accuracy: 16.389999389648438\n",
      "Epoch 2, Loss: 2.3310046195983887, Accuracy: 11.147500038146973, Test Loss: 2.2842605113983154, Test Accuracy: 14.059999465942383\n",
      "Epoch 3, Loss: 2.321211576461792, Accuracy: 11.168333053588867, Test Loss: 2.288464307785034, Test Accuracy: 13.156667709350586\n",
      "Epoch 4, Loss: 2.316265344619751, Accuracy: 11.185416221618652, Test Loss: 2.291658639907837, Test Accuracy: 12.704999923706055\n",
      "Epoch 5, Loss: 2.3133134841918945, Accuracy: 11.193333625793457, Test Loss: 2.2935614585876465, Test Accuracy: 12.434000015258789\n",
      "Epoch 6, Loss: 2.3113253116607666, Accuracy: 11.200555801391602, Test Loss: 2.2948250770568848, Test Accuracy: 12.253334045410156\n",
      "Epoch 7, Loss: 2.309904098510742, Accuracy: 11.205714225769043, Test Loss: 2.295731544494629, Test Accuracy: 12.124285697937012\n",
      "Epoch 8, Loss: 2.308835744857788, Accuracy: 11.209583282470703, Test Loss: 2.296405553817749, Test Accuracy: 12.02750015258789\n",
      "Epoch 9, Loss: 2.3080039024353027, Accuracy: 11.212592124938965, Test Loss: 2.296928644180298, Test Accuracy: 11.952221870422363\n",
      "Epoch 10, Loss: 2.307339906692505, Accuracy: 11.21500015258789, Test Loss: 2.2973501682281494, Test Accuracy: 11.892000198364258\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "        \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    \n",
    "    print(template.format(epoch + 1, \n",
    "                          train_loss.result(), \n",
    "                          train_accuracy.result() * 100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
