{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow: Optimization & Training (Expert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/  \n",
    "공식 홈페이지에서 설명하는 Expert 버젼을 배워보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note for GPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 과정 돌아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logic](image/logic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](image/model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(input_shape, dtype=tf.float64)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64, (3, 3), padding='SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2, 2))(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(0.5)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name='Basic_CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우 공식홈페이지에서 말한 expert한 방법\n",
    "- tf.data 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.mnist\n",
    "\n",
    "# Load Data from MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Add Channel\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "# Data Normalization\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from_tensor_slices()\n",
    "- shuffle()\n",
    "- batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.shuffle(1000)\n",
    "train_ds = train_ds.batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "# No need to shuffle\n",
    "test_ds = test_ds.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data\n",
    "\n",
    "matplotlib 불러와서 데이터 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 28, 28, 1]), TensorShape([32]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_ds.take()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(32, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in train_ds.take(2):\n",
    "    plt.title(label[0].numpy())\n",
    "    plt.imshow(image[0, :, :, 0], 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras로 학습 할 때는 기존과 같지만, train_ds는 generator라서 그대로 넣을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1875 steps\n",
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0498\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0334\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0317\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0320\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0328\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0319\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0317\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0320\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0323\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0313\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0313\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0310\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0306\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0306\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0324\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0301\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0284\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0290\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0298\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0304\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0319\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0300\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0290\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0318\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0311\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0291\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0313\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0298\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0296\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0304\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0302\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0294\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0325\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0275\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0308\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0309\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0329\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0288\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0322\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0301\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0288\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0316\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0313\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0307\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0324\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0284\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0317\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0312\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0299\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0306\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0305\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0340\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0319\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0307\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0316\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0337\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0326\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0342\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0330\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0309\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0308\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0325\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0318\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0314\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0311\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0343\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0322\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0328\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0337\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0329\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0301\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0352\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0302\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0321\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0291\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0346\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0309\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0287\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0307\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0351\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0328\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0297\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0324\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0347\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0281\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0310\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0305\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0347\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0357\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0344\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0329\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0306\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0317\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0328\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0307\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0308\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0341\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0355\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0364\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25664b8bec8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(train_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss Function\n",
    "- Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loss Function를 담을 곳\n",
    "- Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@tf.function - 기존 session 열었던 것처럼 바로 작동 안 하고, 그래프만 만들고 학습이 시작되면 돌아가도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.394169807434082, Accuracy: 10.789999961853027, Test Loss: 2.2733781337738037, Test Accuracy: 19.15999984741211\n",
      "Epoch 2, Loss: 2.3482346534729004, Accuracy: 10.924166679382324, Test Loss: 2.2770986557006836, Test Accuracy: 17.58500099182129\n",
      "Epoch 3, Loss: 2.332921266555786, Accuracy: 10.936111450195312, Test Loss: 2.2839438915252686, Test Accuracy: 15.703333854675293\n",
      "Epoch 4, Loss: 2.3252170085906982, Accuracy: 10.967499732971191, Test Loss: 2.288684368133545, Test Accuracy: 15.197500228881836\n",
      "Epoch 5, Loss: 2.3205599784851074, Accuracy: 10.951333045959473, Test Loss: 2.2909491062164307, Test Accuracy: 14.907999038696289\n",
      "Epoch 6, Loss: 2.317434787750244, Accuracy: 10.981111526489258, Test Loss: 2.2929623126983643, Test Accuracy: 14.720000267028809\n",
      "Epoch 7, Loss: 2.3152010440826416, Accuracy: 11.005714416503906, Test Loss: 2.294090509414673, Test Accuracy: 14.087143898010254\n",
      "Epoch 8, Loss: 2.3135132789611816, Accuracy: 11.01854133605957, Test Loss: 2.2951152324676514, Test Accuracy: 13.879999160766602\n",
      "Epoch 9, Loss: 2.3122177124023438, Accuracy: 11.034444808959961, Test Loss: 2.2956180572509766, Test Accuracy: 13.598889350891113\n",
      "Epoch 10, Loss: 2.311162233352661, Accuracy: 11.03849983215332, Test Loss: 2.2961459159851074, Test Accuracy: 13.479000091552734\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "        \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    \n",
    "    print(template.format(epoch + 1, \n",
    "                          train_loss.result(), \n",
    "                          train_accuracy.result() * 100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result() * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
