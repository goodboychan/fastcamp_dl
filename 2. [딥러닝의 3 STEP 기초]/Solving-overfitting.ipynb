{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network architecture\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1_1 = tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu')\n",
    "        self.conv1_2 = tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu')\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        \n",
    "        self.conv2_1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n",
    "        self.conv2_2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        \n",
    "        self.conv3_1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
    "        self.conv3_2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 22s 0us/step\n"
     ]
    }
   ],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10 # 32x32x3 -> 10 classes\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(1024)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras API model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1563 steps, validate for 313 steps\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4330 - accuracy: 0.4752 - val_loss: 1.1082 - val_accuracy: 0.6087\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9477 - accuracy: 0.6654 - val_loss: 0.8525 - val_accuracy: 0.7033\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7330 - accuracy: 0.7406 - val_loss: 0.7960 - val_accuracy: 0.7236\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.5612 - accuracy: 0.8037 - val_loss: 0.8482 - val_accuracy: 0.7338\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.3933 - accuracy: 0.8627 - val_loss: 0.8878 - val_accuracy: 0.7297\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2456 - accuracy: 0.9142 - val_loss: 1.1325 - val_accuracy: 0.7319\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1713 - accuracy: 0.9407 - val_loss: 1.2911 - val_accuracy: 0.7298\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.1453 - accuracy: 0.9511 - val_loss: 1.3516 - val_accuracy: 0.7379\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.1197 - accuracy: 0.9600 - val_loss: 1.4507 - val_accuracy: 0.7152\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.1124 - accuracy: 0.9626 - val_loss: 1.5756 - val_accuracy: 0.7232\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0991 - accuracy: 0.9670 - val_loss: 1.7962 - val_accuracy: 0.7235\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1034 - accuracy: 0.9676 - val_loss: 1.6275 - val_accuracy: 0.7297\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0927 - accuracy: 0.9700 - val_loss: 1.8246 - val_accuracy: 0.7223\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.0940 - accuracy: 0.9698 - val_loss: 1.8961 - val_accuracy: 0.7283\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0941 - accuracy: 0.9704 - val_loss: 1.9134 - val_accuracy: 0.7176\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0771 - accuracy: 0.9760 - val_loss: 2.2468 - val_accuracy: 0.7140\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0898 - accuracy: 0.9734 - val_loss: 2.0026 - val_accuracy: 0.7170\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0793 - accuracy: 0.9759 - val_loss: 2.1601 - val_accuracy: 0.7208\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0827 - accuracy: 0.9747 - val_loss: 2.0502 - val_accuracy: 0.7249\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0799 - accuracy: 0.9763 - val_loss: 2.5070 - val_accuracy: 0.7003\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0776 - accuracy: 0.9770 - val_loss: 2.3324 - val_accuracy: 0.7150\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0756 - accuracy: 0.9773 - val_loss: 2.4027 - val_accuracy: 0.7116\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0758 - accuracy: 0.9777 - val_loss: 2.3313 - val_accuracy: 0.7218\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9773 - val_loss: 2.2866 - val_accuracy: 0.7091\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0700 - accuracy: 0.9791 - val_loss: 2.5003 - val_accuracy: 0.7148\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0711 - accuracy: 0.9794 - val_loss: 2.7447 - val_accuracy: 0.7086\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0785 - accuracy: 0.9775 - val_loss: 2.4583 - val_accuracy: 0.7058\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0703 - accuracy: 0.9807 - val_loss: 2.4404 - val_accuracy: 0.7228\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0710 - accuracy: 0.9803 - val_loss: 2.7501 - val_accuracy: 0.7157\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9787 - val_loss: 2.5087 - val_accuracy: 0.7041\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0705 - accuracy: 0.9805 - val_loss: 2.9832 - val_accuracy: 0.6986\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.0730 - accuracy: 0.9802 - val_loss: 2.5832 - val_accuracy: 0.7125\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0656 - accuracy: 0.9829 - val_loss: 2.9223 - val_accuracy: 0.7145\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0788 - accuracy: 0.9789 - val_loss: 2.8292 - val_accuracy: 0.7088\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0809 - accuracy: 0.9793 - val_loss: 2.7579 - val_accuracy: 0.7052\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0641 - accuracy: 0.9826 - val_loss: 2.9668 - val_accuracy: 0.7077\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0725 - accuracy: 0.9815 - val_loss: 3.1841 - val_accuracy: 0.7060\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0727 - accuracy: 0.9816 - val_loss: 2.8351 - val_accuracy: 0.7067\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0734 - accuracy: 0.9815 - val_loss: 3.0765 - val_accuracy: 0.7079\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.0702 - accuracy: 0.9819 - val_loss: 3.0255 - val_accuracy: 0.7007\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0582 - accuracy: 0.9852 - val_loss: 3.2776 - val_accuracy: 0.6997\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0744 - accuracy: 0.9811 - val_loss: 3.3028 - val_accuracy: 0.7026\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0776 - accuracy: 0.9813 - val_loss: 3.2730 - val_accuracy: 0.7081\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0610 - accuracy: 0.9839 - val_loss: 3.5745 - val_accuracy: 0.6950\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0782 - accuracy: 0.9810 - val_loss: 3.3802 - val_accuracy: 0.6995\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9824 - val_loss: 3.6525 - val_accuracy: 0.6986\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0787 - accuracy: 0.9824 - val_loss: 3.1286 - val_accuracy: 0.7005\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0675 - accuracy: 0.9838 - val_loss: 3.3391 - val_accuracy: 0.7009\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0682 - accuracy: 0.9841 - val_loss: 3.4964 - val_accuracy: 0.7062\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0750 - accuracy: 0.9826 - val_loss: 3.5802 - val_accuracy: 0.6902\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0644 - accuracy: 0.9846 - val_loss: 3.9453 - val_accuracy: 0.6962\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9829 - val_loss: 3.5515 - val_accuracy: 0.7047\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0723 - accuracy: 0.9833 - val_loss: 4.1153 - val_accuracy: 0.6927\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0682 - accuracy: 0.9845 - val_loss: 3.9965 - val_accuracy: 0.7033\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0776 - accuracy: 0.9829 - val_loss: 3.5555 - val_accuracy: 0.7022\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0670 - accuracy: 0.9840 - val_loss: 3.5248 - val_accuracy: 0.7011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9842 - val_loss: 3.8667 - val_accuracy: 0.7049\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0686 - accuracy: 0.9850 - val_loss: 4.2643 - val_accuracy: 0.6942\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9828 - val_loss: 4.1043 - val_accuracy: 0.7021\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0732 - accuracy: 0.9849 - val_loss: 3.8420 - val_accuracy: 0.7079\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0709 - accuracy: 0.9846 - val_loss: 4.0454 - val_accuracy: 0.6918\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9842 - val_loss: 4.4040 - val_accuracy: 0.7020\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0713 - accuracy: 0.9851 - val_loss: 4.1435 - val_accuracy: 0.7004\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0665 - accuracy: 0.9858 - val_loss: 4.4678 - val_accuracy: 0.6994\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0733 - accuracy: 0.9846 - val_loss: 4.4215 - val_accuracy: 0.7030\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0744 - accuracy: 0.9843 - val_loss: 4.5790 - val_accuracy: 0.7042\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0694 - accuracy: 0.9855 - val_loss: 4.3768 - val_accuracy: 0.6995\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9846 - val_loss: 4.5051 - val_accuracy: 0.6974\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0842 - accuracy: 0.9836 - val_loss: 4.0797 - val_accuracy: 0.7018\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0649 - accuracy: 0.9860 - val_loss: 4.6405 - val_accuracy: 0.7007\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0845 - accuracy: 0.9829 - val_loss: 4.9428 - val_accuracy: 0.6889\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9855 - val_loss: 4.6362 - val_accuracy: 0.7005\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0672 - accuracy: 0.9866 - val_loss: 5.2336 - val_accuracy: 0.6889\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0784 - accuracy: 0.9847 - val_loss: 4.7696 - val_accuracy: 0.6969\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0786 - accuracy: 0.9853 - val_loss: 5.0098 - val_accuracy: 0.7048\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0829 - accuracy: 0.9852 - val_loss: 4.8806 - val_accuracy: 0.6961\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0810 - accuracy: 0.9850 - val_loss: 5.2604 - val_accuracy: 0.6877\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9856 - val_loss: 4.5208 - val_accuracy: 0.6934\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0707 - accuracy: 0.9857 - val_loss: 4.4628 - val_accuracy: 0.7041\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0781 - accuracy: 0.9861 - val_loss: 4.9585 - val_accuracy: 0.6893\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0809 - accuracy: 0.9859 - val_loss: 5.4744 - val_accuracy: 0.6957\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0879 - accuracy: 0.9855 - val_loss: 4.6832 - val_accuracy: 0.6985\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0749 - accuracy: 0.9858 - val_loss: 5.2491 - val_accuracy: 0.6958\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0755 - accuracy: 0.9859 - val_loss: 5.3361 - val_accuracy: 0.6936\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9864 - val_loss: 5.2628 - val_accuracy: 0.6893\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0782 - accuracy: 0.9862 - val_loss: 5.3001 - val_accuracy: 0.7077\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0768 - accuracy: 0.9871 - val_loss: 4.7898 - val_accuracy: 0.6896\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0878 - accuracy: 0.9840 - val_loss: 4.8963 - val_accuracy: 0.7086\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0724 - accuracy: 0.9873 - val_loss: 5.1482 - val_accuracy: 0.7041\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9870 - val_loss: 6.2019 - val_accuracy: 0.6925\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0855 - accuracy: 0.9860 - val_loss: 5.8208 - val_accuracy: 0.6867\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9868 - val_loss: 5.8486 - val_accuracy: 0.7023\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0850 - accuracy: 0.9870 - val_loss: 6.3117 - val_accuracy: 0.6993\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0707 - accuracy: 0.9880 - val_loss: 5.9005 - val_accuracy: 0.6976\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9859 - val_loss: 5.9962 - val_accuracy: 0.7035\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0820 - accuracy: 0.9874 - val_loss: 5.8857 - val_accuracy: 0.6897\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0899 - accuracy: 0.9856 - val_loss: 6.4509 - val_accuracy: 0.6896\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0937 - accuracy: 0.9862 - val_loss: 6.4927 - val_accuracy: 0.6956\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0784 - accuracy: 0.9875 - val_loss: 6.3150 - val_accuracy: 0.6957\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0853 - accuracy: 0.9873 - val_loss: 6.0726 - val_accuracy: 0.7018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x215f9bf7f88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLNReluBlock(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super(ConvLNReluBlock, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters, kernel_size, padding='same', use_bias=False)\n",
    "        self.ln = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv(x)\n",
    "        x = self.ln(x) # LayerNormalization does not affect training weights\n",
    "        return tf.nn.relu(x)\n",
    "        \n",
    "\n",
    "# Define network architecture\n",
    "class MyModelLN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModelLN, self).__init__()\n",
    "        self.conv1_1 = ConvLNReluBlock(16, (3, 3))\n",
    "        self.conv1_2 = ConvLNReluBlock(16, (3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        \n",
    "        self.conv2_1 = ConvLNReluBlock(32, (3, 3))\n",
    "        self.conv2_2 = ConvLNReluBlock(32, (3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "        \n",
    "        self.conv3_1 = ConvLNReluBlock(64, (3, 3))\n",
    "        self.conv3_2 = ConvLNReluBlock(64, (3, 3))\n",
    "        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu', \n",
    "                                            kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax', \n",
    "                                            kernel_regularizer = tf.keras.regularizers.l2(0.01))\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1563 steps, validate for 313 steps\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.2318 - accuracy: 0.3800 - val_loss: 1.4979 - val_accuracy: 0.5092\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2661 - accuracy: 0.5907 - val_loss: 1.1265 - val_accuracy: 0.6449\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0893 - accuracy: 0.6579 - val_loss: 1.0022 - val_accuracy: 0.6851\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9894 - accuracy: 0.6940 - val_loss: 1.0308 - val_accuracy: 0.6814\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9212 - accuracy: 0.7185 - val_loss: 0.9180 - val_accuracy: 0.7172\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8715 - accuracy: 0.7366 - val_loss: 0.8514 - val_accuracy: 0.7431\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8253 - accuracy: 0.7528 - val_loss: 0.8643 - val_accuracy: 0.7391\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7933 - accuracy: 0.7645 - val_loss: 0.8111 - val_accuracy: 0.7648\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7560 - accuracy: 0.7756 - val_loss: 0.8355 - val_accuracy: 0.7530\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7316 - accuracy: 0.7846 - val_loss: 0.8778 - val_accuracy: 0.7394\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7110 - accuracy: 0.7945 - val_loss: 0.7898 - val_accuracy: 0.7644\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6866 - accuracy: 0.8000 - val_loss: 0.8319 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6627 - accuracy: 0.8089 - val_loss: 0.7742 - val_accuracy: 0.7759\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6410 - accuracy: 0.8180 - val_loss: 0.7752 - val_accuracy: 0.7711\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6202 - accuracy: 0.8258 - val_loss: 0.7612 - val_accuracy: 0.7771\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6013 - accuracy: 0.8323 - val_loss: 0.7797 - val_accuracy: 0.7720\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5856 - accuracy: 0.8372 - val_loss: 0.8140 - val_accuracy: 0.7610\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5646 - accuracy: 0.8441 - val_loss: 0.7880 - val_accuracy: 0.7680\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5533 - accuracy: 0.8463 - val_loss: 0.7465 - val_accuracy: 0.7822\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5368 - accuracy: 0.8538 - val_loss: 0.7898 - val_accuracy: 0.7728\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5234 - accuracy: 0.8587 - val_loss: 0.7755 - val_accuracy: 0.7759\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5115 - accuracy: 0.8650 - val_loss: 0.7556 - val_accuracy: 0.7875\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4988 - accuracy: 0.8691 - val_loss: 0.7796 - val_accuracy: 0.7804\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4808 - accuracy: 0.8743 - val_loss: 0.7987 - val_accuracy: 0.7759\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4774 - accuracy: 0.8771 - val_loss: 0.8105 - val_accuracy: 0.7774\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4624 - accuracy: 0.8821 - val_loss: 0.7876 - val_accuracy: 0.7865\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4533 - accuracy: 0.8863 - val_loss: 0.7940 - val_accuracy: 0.7841\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4494 - accuracy: 0.8885 - val_loss: 0.7821 - val_accuracy: 0.7893\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4347 - accuracy: 0.8921 - val_loss: 0.8248 - val_accuracy: 0.7752\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4256 - accuracy: 0.8945 - val_loss: 0.8088 - val_accuracy: 0.7823\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4158 - accuracy: 0.8999 - val_loss: 0.8068 - val_accuracy: 0.7857\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4064 - accuracy: 0.9037 - val_loss: 0.8407 - val_accuracy: 0.7831\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3994 - accuracy: 0.9051 - val_loss: 0.8656 - val_accuracy: 0.7719\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3942 - accuracy: 0.9083 - val_loss: 0.8080 - val_accuracy: 0.7893\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3838 - accuracy: 0.9111 - val_loss: 0.8576 - val_accuracy: 0.7769\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3802 - accuracy: 0.9142 - val_loss: 0.8891 - val_accuracy: 0.7774\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3716 - accuracy: 0.9165 - val_loss: 0.8358 - val_accuracy: 0.7818\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3634 - accuracy: 0.9193 - val_loss: 0.8685 - val_accuracy: 0.7833\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3575 - accuracy: 0.9217 - val_loss: 0.8881 - val_accuracy: 0.7776\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3501 - accuracy: 0.9245 - val_loss: 0.8931 - val_accuracy: 0.7705\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3471 - accuracy: 0.9266 - val_loss: 0.9058 - val_accuracy: 0.7835\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3363 - accuracy: 0.9292 - val_loss: 0.8911 - val_accuracy: 0.7764\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3325 - accuracy: 0.9300 - val_loss: 0.9333 - val_accuracy: 0.7785\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3350 - accuracy: 0.9300 - val_loss: 0.8962 - val_accuracy: 0.7898\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3253 - accuracy: 0.9335 - val_loss: 0.9226 - val_accuracy: 0.7776\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3177 - accuracy: 0.9368 - val_loss: 0.9665 - val_accuracy: 0.7731\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3111 - accuracy: 0.9388 - val_loss: 0.9219 - val_accuracy: 0.7713\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3099 - accuracy: 0.9396 - val_loss: 0.9702 - val_accuracy: 0.7738\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3098 - accuracy: 0.9389 - val_loss: 0.9368 - val_accuracy: 0.7778\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2961 - accuracy: 0.9450 - val_loss: 0.9884 - val_accuracy: 0.7640\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3038 - accuracy: 0.9410 - val_loss: 0.9594 - val_accuracy: 0.7713\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2934 - accuracy: 0.9452 - val_loss: 1.0194 - val_accuracy: 0.7714\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2904 - accuracy: 0.9452 - val_loss: 0.9987 - val_accuracy: 0.7718\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2890 - accuracy: 0.9461 - val_loss: 0.9679 - val_accuracy: 0.7747\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2820 - accuracy: 0.9477 - val_loss: 1.0194 - val_accuracy: 0.7675\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2810 - accuracy: 0.9483 - val_loss: 0.9687 - val_accuracy: 0.7774\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2773 - accuracy: 0.9496 - val_loss: 0.9460 - val_accuracy: 0.7727\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2779 - accuracy: 0.9488 - val_loss: 1.0850 - val_accuracy: 0.7621\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2701 - accuracy: 0.9514 - val_loss: 1.0216 - val_accuracy: 0.7797\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2644 - accuracy: 0.9531 - val_loss: 1.0014 - val_accuracy: 0.7789\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2666 - accuracy: 0.9529 - val_loss: 1.0192 - val_accuracy: 0.7766\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2623 - accuracy: 0.9542 - val_loss: 1.0700 - val_accuracy: 0.7652\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2657 - accuracy: 0.9537 - val_loss: 1.0120 - val_accuracy: 0.7768\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2530 - accuracy: 0.9581 - val_loss: 1.0364 - val_accuracy: 0.7749\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2571 - accuracy: 0.9566 - val_loss: 1.0287 - val_accuracy: 0.7701\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2589 - accuracy: 0.9558 - val_loss: 1.0529 - val_accuracy: 0.7691\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2545 - accuracy: 0.9572 - val_loss: 1.0144 - val_accuracy: 0.7745\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2483 - accuracy: 0.9600 - val_loss: 1.0212 - val_accuracy: 0.7760\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2484 - accuracy: 0.9582 - val_loss: 1.0014 - val_accuracy: 0.7764\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2431 - accuracy: 0.9606 - val_loss: 1.1529 - val_accuracy: 0.7607\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.2406 - accuracy: 0.9617 - val_loss: 1.0200 - val_accuracy: 0.7746\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2443 - accuracy: 0.9595 - val_loss: 1.0777 - val_accuracy: 0.7786\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2416 - accuracy: 0.9610 - val_loss: 1.0934 - val_accuracy: 0.7678\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2425 - accuracy: 0.9601 - val_loss: 1.0844 - val_accuracy: 0.7724\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2299 - accuracy: 0.9644 - val_loss: 1.0728 - val_accuracy: 0.7716\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2338 - accuracy: 0.9633 - val_loss: 1.0835 - val_accuracy: 0.7665\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2326 - accuracy: 0.9636 - val_loss: 1.0507 - val_accuracy: 0.7722\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2308 - accuracy: 0.9638 - val_loss: 1.1321 - val_accuracy: 0.7661\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2306 - accuracy: 0.9640 - val_loss: 1.0482 - val_accuracy: 0.7719\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2233 - accuracy: 0.9663 - val_loss: 1.0481 - val_accuracy: 0.7658\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2285 - accuracy: 0.9647 - val_loss: 1.0988 - val_accuracy: 0.7692\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.2287 - accuracy: 0.9645 - val_loss: 1.0544 - val_accuracy: 0.7689\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2205 - accuracy: 0.9663 - val_loss: 1.0620 - val_accuracy: 0.7773\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2247 - accuracy: 0.9661 - val_loss: 1.0046 - val_accuracy: 0.7716\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2215 - accuracy: 0.9662 - val_loss: 1.1067 - val_accuracy: 0.7732\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2159 - accuracy: 0.9677 - val_loss: 1.1087 - val_accuracy: 0.7755\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2182 - accuracy: 0.9665 - val_loss: 1.0842 - val_accuracy: 0.7736\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2150 - accuracy: 0.9677 - val_loss: 1.1038 - val_accuracy: 0.7650\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2161 - accuracy: 0.9674 - val_loss: 1.0848 - val_accuracy: 0.7727\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2126 - accuracy: 0.9688 - val_loss: 1.1145 - val_accuracy: 0.7688\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2156 - accuracy: 0.9669 - val_loss: 1.0660 - val_accuracy: 0.7703\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2063 - accuracy: 0.9702 - val_loss: 1.1500 - val_accuracy: 0.7706\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2105 - accuracy: 0.9694 - val_loss: 1.1205 - val_accuracy: 0.7677\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2033 - accuracy: 0.9713 - val_loss: 1.1117 - val_accuracy: 0.7651\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2102 - accuracy: 0.9683 - val_loss: 1.1164 - val_accuracy: 0.7654\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2011 - accuracy: 0.9708 - val_loss: 1.1037 - val_accuracy: 0.7689\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2034 - accuracy: 0.9712 - val_loss: 1.1053 - val_accuracy: 0.7635\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2026 - accuracy: 0.9709 - val_loss: 1.1236 - val_accuracy: 0.7787\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1985 - accuracy: 0.9721 - val_loss: 1.1690 - val_accuracy: 0.7627\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.2053 - accuracy: 0.9701 - val_loss: 1.1779 - val_accuracy: 0.7651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2188a0e6548>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModelLN()\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
